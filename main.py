import os
import sys
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import Dict, Any, List
import logging

# Importar nuestro sistema RAG con embeddings remotos
from rag_system import RemoteEmbeddingRAG

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(
    title="Manual Mantenimiento API",
    description="API RAG para consultas del Manual de Mantenimiento de Salones del Reino",
    version="2.0.0-remote-embeddings"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Inicializar sistema RAG con embeddings remotos
logger.info("üöÄ Inicializando API con Remote Embeddings...")
rag_system = RemoteEmbeddingRAG()

# Modelos de datos
class QueryRequest(BaseModel):
    query: str
    user_id: str = "default"

class QueryResponse(BaseModel):
    answer: str
    sources: List[str] = []
    metadata: Dict[str, Any] = {}

@app.on_event("startup")
async def startup_event():
    """Eventos de inicio"""
    logger.info("‚úÖ Manual Mantenimiento API iniciada exitosamente")
    logger.info("üß† Usando embeddings remotos (HuggingFace)")
    logger.info("üîç B√∫squeda vectorial completa en Qdrant")
    
    # Verificar estado del RAG
    health = rag_system.health_check()
    if health["overall_status"] == "healthy":
        logger.info("‚úÖ Sistema RAG completamente operacional")
    else:
        logger.warning("‚ö†Ô∏è Sistema RAG en modo limitado - usando respuestas mock")

@app.get("/")
async def root():
    return {
        "message": "Manual Mantenimiento API",
        "status": "running",
        "version": "2.0.0-remote-embeddings",
        "docs": "/docs",
        "features": {
            "vector_search": True,
            "remote_embeddings": True,
            "groq_llm": True,
            "render_free_compatible": True
        },
        "endpoints": {
            "query": "/query",
            "health": "/health", 
            "rag_status": "/rag-status",
            "test_queries": "/test-queries",
            "secrets_check": "/secrets-check"
        }
    }

@app.get("/health")
async def health_check():
    """Health check b√°sico de la API"""
    return {
        "status": "healthy",
        "service": "manual-mantenimiento-api",
        "api_status": "operational",
        "embedding_method": "remote_huggingface",
        "memory_optimized": True
    }

@app.get("/rag-status")
async def rag_status():
    """Estado detallado del sistema RAG"""
    health = rag_system.health_check()
    
    return {
        "rag_system": health,
        "ready_for_queries": health["operational"],
        "embedding_provider": "HuggingFace Inference API",
        "vector_database": "Qdrant Cloud",
        "llm_provider": "Groq",
        "mode": "remote_embeddings_full_rag" if health["operational"] else "mock_fallback",
        "advantages": [
            "‚úÖ B√∫squeda vectorial completa",
            "‚úÖ Compatible con Render free plan", 
            "‚úÖ Sin dependencias pesadas locales",
            "‚úÖ Embeddings de calidad profesional"
        ]
    }

@app.get("/secrets-check")
async def secrets_check():
    """Verificar que los secrets est√°n configurados"""
    secrets = {
        "QDRANT_URL": bool(os.getenv("QDRANT_URL")),
        "QDRANT_API_KEY": bool(os.getenv("QDRANT_API_KEY")), 
        "GROQ_API_KEY": bool(os.getenv("GROQ_API_KEY")),
        "QDRANT_COLLECTION_NAME": bool(os.getenv("QDRANT_COLLECTION_NAME"))
    }
    
    all_configured = all(secrets.values())
    
    return {
        "secrets_configured": secrets,
        "all_ready": all_configured,
        "missing_secrets": [key for key, value in secrets.items() if not value],
        "status": "ready" if all_configured else "incomplete",
        "next_steps": [
            "1. Configure missing secrets in Render Environment Variables",
            "2. Redeploy the service",
            "3. Upload manual using Kaggle",
            "4. Test vector search functionality"
        ] if not all_configured else [
            "‚úÖ All secrets configured",
            "üîÑ Upload manual to Qdrant using Kaggle",
            "üß™ Test queries to verify functionality"
        ]
    }

@app.post("/query", response_model=QueryResponse)
async def query_manual(request: QueryRequest):
    """Endpoint principal para consultas al manual con b√∫squeda vectorial"""
    try:
        logger.info(f"üîç Nueva consulta: {request.query[:50]}... (usuario: {request.user_id})")
        
        # Procesar consulta con el sistema RAG de embeddings remotos
        result = await rag_system.query(request.query, request.user_id)
        
        return QueryResponse(
            answer=result["answer"],
            sources=result.get("sources", []),
            metadata=result.get("metadata", {})
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error procesando consulta: {str(e)}")
        raise HTTPException(
            status_code=500, 
            detail=f"Error procesando consulta: {str(e)}"
        )

@app.get("/test-queries")
async def test_queries():
    """Endpoint para probar consultas comunes con b√∫squeda vectorial"""
    test_cases = [
        "¬øC√≥mo reparar aire acondicionado que gotea?",
        "¬øC√≥mo arreglar grietas en la pared?", 
        "¬øC√≥mo pintar paredes da√±adas?",
        "¬øC√≥mo desobstruir registros de agua?",
        "¬øQu√© mantenimiento necesitan las luminarias?",
        "¬øQu√© hacer con √≥xido en elementos met√°licos?",
        "¬øC√≥mo inspeccionar el sistema el√©ctrico?"
    ]
    
    results = {}
    for query in test_cases:
        try:
            result = await rag_system.query(query, "test_user")
            results[query] = {
                "answer_preview": result["answer"][:150] + "...",
                "sources_count": len(result.get("sources", [])),
                "status": "success",
                "search_method": result.get("metadata", {}).get("search_method", "unknown"),
                "system_status": result.get("metadata", {}).get("system_status", "unknown")
            }
        except Exception as e:
            results[query] = {
                "error": str(e),
                "status": "error"
            }
    
    successful_tests = len([r for r in results.values() if r.get("status") == "success"])
    
    return {
        "test_results": results,
        "summary": {
            "total_tests": len(test_cases),
            "successful_tests": successful_tests,
            "success_rate": f"{(successful_tests/len(test_cases)*100):.1f}%"
        },
        "embedding_method": "remote_huggingface",
        "vector_search": "qdrant_cloud"
    }

@app.get("/environment")
async def get_environment():
    """Ver configuraci√≥n del entorno (SIN exponer secrets)"""
    return {
        "secrets_status": {
            "qdrant_url_configured": bool(os.getenv("QDRANT_URL")),
            "qdrant_api_key_configured": bool(os.getenv("QDRANT_API_KEY")),
            "groq_api_key_configured": bool(os.getenv("GROQ_API_KEY")),
        },
        "collection_name": os.getenv("QDRANT_COLLECTION_NAME", "manual_mantenimiento"),
        "python_version": sys.version.split()[0],
        "environment": os.getenv("ENVIRONMENT", "production"),
        "api_version": "2.0.0-remote-embeddings",
        "features": {
            "rag_enabled": True,
            "embedding_method": "remote_huggingface",
            "vector_search": "qdrant_cloud",
            "llm_provider": "groq",
            "memory_optimized": True
        }
    }

@app.get("/system-info")
async def system_info():
    """Informaci√≥n t√©cnica del sistema"""
    return {
        "architecture": {
            "embeddings": "HuggingFace Inference API (remote)",
            "vector_database": "Qdrant Cloud",
            "llm": "Groq (Llama 3.1 70B)",
            "api_framework": "FastAPI",
            "deployment": "Render (free plan compatible)"
        },
        "workflow": [
            "1. üë§ Usuario env√≠a consulta",
            "2. üî¢ HuggingFace genera embedding remoto",
            "3. üîç Qdrant busca vectores similares",
            "4. üìã Obtiene chunks relevantes del manual",
            "5. ü§ñ Groq genera respuesta contextual",
            "6. ‚úÖ Usuario recibe respuesta del manual"
        ],
        "benefits": [
            "‚úÖ B√∫squeda vectorial sem√°ntica completa",
            "‚úÖ Compatible con planes gratuitos",
            "‚úÖ Sin limitaciones de memoria local",
            "‚úÖ Respuestas basadas en manual oficial",
            "‚úÖ Escalable y mantenible"
        ]
    }

if __name__ == "__main__":
    import uvicorn
    port = int(os.environ.get("PORT", 8000))
    uvicorn.run(app, host="0.0.0.0", port=port)
