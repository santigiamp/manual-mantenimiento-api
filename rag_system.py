import os
import logging
import httpx
import json
from typing import List, Dict, Any, Optional
import uuid
import asyncio

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RemoteEmbeddingRAG:
    def __init__(self):
        """RAG System usando embeddings remotos con im√°genes REALES del manual"""
        try:
            # Configuraci√≥n desde variables de entorno
            self.qdrant_url = os.getenv("QDRANT_URL")
            self.qdrant_api_key = os.getenv("QDRANT_API_KEY") 
            self.collection_name = os.getenv("QDRANT_COLLECTION_NAME", "manual_mantenimiento")
            self.groq_api_key = os.getenv("GROQ_API_KEY")
            
            # URLs para APIs externas
            self.qdrant_base_url = f"{self.qdrant_url.rstrip('/')}/collections/{self.collection_name}"
            
            # Log de configuraci√≥n (sin exponer secrets)
            logger.info("üöÄ Inicializando Remote RAG con im√°genes REALES del manual...")
            logger.info(f"‚úÖ QDRANT_URL configurada: {bool(self.qdrant_url)}")
            logger.info(f"‚úÖ QDRANT_API_KEY configurada: {bool(self.qdrant_api_key)}")
            logger.info(f"‚úÖ GROQ_API_KEY configurada: {bool(self.groq_api_key)}")
            logger.info(f"üì¶ Collection: {self.collection_name}")
            logger.info("üñºÔ∏è Modo: IM√ÅGENES REALES del PDF")
            
            # Validar configuraci√≥n
            missing_vars = []
            if not self.qdrant_url:
                missing_vars.append("QDRANT_URL")
            if not self.qdrant_api_key:
                missing_vars.append("QDRANT_API_KEY")
            if not self.groq_api_key:
                missing_vars.append("GROQ_API_KEY")
                
            if missing_vars:
                logger.warning(f"‚ö†Ô∏è Variables faltantes: {', '.join(missing_vars)}")
                logger.warning("üîÑ Sistema funcionar√° en modo limitado")
                self.operational = False
            else:
                logger.info("‚úÖ Todas las configuraciones listas")
                self.operational = True
                
        except Exception as e:
            logger.error(f"‚ùå Error inicializando RAG: {str(e)}")
            self.operational = False
    
    async def get_remote_embedding(self, text: str) -> List[float]:
        """Obtener embedding usando HuggingFace Inference API"""
        try:
            logger.debug(f"üî¢ Generando embedding para: {text[:50]}...")
            
            url = "https://api-inference.huggingface.co/pipeline/feature-extraction/sentence-transformers/all-MiniLM-L6-v2"
            headers = {"Content-Type": "application/json"}
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    url,
                    headers=headers,
                    json={"inputs": text, "options": {"wait_for_model": True}}
                )
                
                if response.status_code == 200:
                    embedding = response.json()
                    
                    if isinstance(embedding, list) and len(embedding) > 0:
                        if isinstance(embedding[0], list):
                            result = embedding[0]
                        else:
                            result = embedding
                        
                        logger.debug(f"‚úÖ Embedding generado: {len(result)} dimensiones")
                        return result
                    else:
                        raise ValueError("Formato de embedding inesperado")
                        
                elif response.status_code == 503:
                    logger.warning("‚è≥ Modelo carg√°ndose, reintentando...")
                    await asyncio.sleep(2)
                    response = await client.post(url, headers=headers, json={"inputs": text})
                    if response.status_code == 200:
                        embedding = response.json()
                        return embedding[0] if isinstance(embedding[0], list) else embedding
                    else:
                        raise Exception(f"Error despu√©s de reintento: {response.status_code}")
                else:
                    raise Exception(f"Error HuggingFace: {response.status_code} - {response.text}")
                    
        except Exception as e:
            logger.error(f"‚ùå Error generando embedding: {str(e)}")
            if not self.operational:
                logger.warning("üîÑ Sistema no operacional, usando embedding mock")
            return [0.0] * 384  # Fallback con dimensiones correctas
    
    async def search_qdrant_vectors(self, query_embedding: List[float], limit: int = 3) -> List[Dict[str, Any]]:
        """Buscar vectores similares en Qdrant - Solo resultados REALES"""
        try:
            if not self.operational:
                logger.error("‚ùå Sistema no operacional - Qdrant no configurado")
                return []
            
            logger.debug(f"üîç Buscando en Qdrant: {len(query_embedding)} dim vector")
            
            search_url = f"{self.qdrant_base_url}/points/search"
            
            headers = {
                "api-key": self.qdrant_api_key,
                "Content-Type": "application/json"
            }
            
            search_payload = {
                "vector": query_embedding,
                "limit": limit,
                "with_payload": True,
                "with_vector": False,
                "score_threshold": 0.1  # Filtro m√≠nimo de relevancia
            }
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    search_url,
                    headers=headers,
                    json=search_payload
                )
                
                if response.status_code == 200:
                    search_result = response.json()
                    results = []
                    
                    for hit in search_result.get("result", []):
                        payload = hit.get("payload", {})
                        
                        # Procesar im√°genes REALES del manual
                        images = payload.get('images', [])
                        processed_images = []
                        
                        for img in images:
                            # Validar que sea una imagen real (no mock)
                            if img.get('image_url') and not 'placeholder' in img.get('image_url', ''):
                                processed_images.append({
                                    'url': img.get('image_url'),
                                    'description': img.get('description', 'Imagen t√©cnica del manual'),
                                    'extracted_text': img.get('extracted_text', ''),
                                    'context': img.get('context', ''),
                                    'filename': img.get('filename', ''),
                                    'page': payload.get('page', 0),
                                    'width': img.get('width', 0),
                                    'height': img.get('height', 0)
                                })
                        
                        result_item = {
                            'content': payload.get('content', ''),
                            'page': payload.get('page', 0),
                            'section': payload.get('section', ''),
                            'title': payload.get('title', ''),
                            'score': hit.get('score', 0.0),
                            'has_images': len(processed_images) > 0,
                            'image_count': len(processed_images),
                            'images': processed_images,
                            'chunk_type': payload.get('chunk_type', 'unknown')
                        }
                        
                        results.append(result_item)
                    
                    logger.info(f"‚úÖ Encontrados {len(results)} chunks relevantes")
                    
                    # Log de im√°genes REALES encontradas
                    total_real_images = sum(len(r.get('images', [])) for r in results)
                    if total_real_images > 0:
                        logger.info(f"üñºÔ∏è Total im√°genes REALES: {total_real_images}")
                        for r in results:
                            if r['has_images']:
                                logger.info(f"üì∏ P√°gina {r['page']}: {r['image_count']} imagen(es)")
                    
                    return results
                    
                elif response.status_code == 404:
                    logger.error("üìã Colecci√≥n no existe en Qdrant")
                    logger.error("üí° Ejecuta el script de Kaggle primero para procesar el manual")
                    return []
                else:
                    logger.error(f"‚ùå Error Qdrant: {response.status_code} - {response.text}")
                    return []
                    
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda vectorial: {str(e)}")
            return []
    
    async def generate_answer_with_groq(self, query: str, context_chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Generar respuesta usando Groq LLM incluyendo informaci√≥n de im√°genes REALES"""
        try:
            if not self.groq_api_key:
                logger.error("‚ùå Groq API key no configurada")
                return self._format_basic_answer(context_chunks)
            
            if not context_chunks:
                return {
                    "text": "‚ùå No encontr√© informaci√≥n relevante en el manual para tu consulta. Verifica que el manual haya sido procesado correctamente en Kaggle.",
                    "images": []
                }
            
            # Preparar contexto incluyendo im√°genes REALES
            context_parts = []
            relevant_images = []
            
            for chunk in context_chunks:
                # Contexto de texto
                context_parts.append(f"**{chunk['title']} (P√°gina {chunk['page']})**\n{chunk['content']}")
                
                # Recopilar im√°genes REALES
                for img in chunk.get('images', []):
                    # Validar que sea imagen real del manual
                    if img.get('url') and not 'placeholder' in img.get('url', ''):
                        relevant_images.append({
                            'url': img['url'],
                            'description': img['description'],
                            'page': img['page'],
                            'filename': img.get('filename', ''),
                            'width': img.get('width', 0),
                            'height': img.get('height', 0),
                            'extracted_text': img.get('extracted_text', ''),
                            'context': img.get('context', '')
                        })
            
            context = "\n\n".join(context_parts)
            
            # Informaci√≥n sobre material visual disponible
            visual_info = ""
            if relevant_images:
                visual_descriptions = []
                for img in relevant_images:
                    desc = f"- P√°gina {img['page']}: {img['description']}"
                    if img.get('extracted_text'):
                        desc += f" (Elementos: {img['extracted_text'][:50]})"
                    visual_descriptions.append(desc)
                
                visual_info = f"\n\nüì∏ MATERIAL VISUAL T√âCNICO DISPONIBLE ({len(relevant_images)} imagen(es)):\n" + "\n".join(visual_descriptions)
            
            # Prompt optimizado para referencias a im√°genes REALES
            prompt = f"""Eres un asistente experto en mantenimiento de Salones del Reino basado en el Manual oficial.
Responde la pregunta usando √öNICAMENTE el contexto proporcionado del manual.

**CONTEXTO DEL MANUAL:**
{context}{visual_info}

**PREGUNTA DEL USUARIO:**
{query}

**INSTRUCCIONES:**
- Responde en espa√±ol con informaci√≥n pr√°ctica del manual
- Usa emojis relevantes: üîß‚ö°üè†üí°üö∞üñºÔ∏è‚ö†Ô∏è‚úÖ‚ùå
- Si hay pasos espec√≠ficos, n√∫meralos claramente
- Marca advertencias importantes como ‚ö†Ô∏è IMPORTANTE
- Si hay material visual disponible, menciona espec√≠ficamente las im√°genes t√©cnicas que complementan la explicaci√≥n
- Incluye referencias a p√°ginas del manual
- Si el material visual muestra procedimientos, menciona qu√© elementos se pueden ver
- Mant√©n un tono profesional pero amigable
- Si no hay suficiente informaci√≥n, dilo claramente

**RESPUESTA:**"""

            headers = {
                "Authorization": f"Bearer {self.groq_api_key}",
                "Content-Type": "application/json"
            }
            
            payload = {
                "model": "llama-3.1-70b-versatile",
                "messages": [
                    {
                        "role": "system", 
                        "content": "Eres un experto en mantenimiento de Salones del Reino. Siempre basas tus respuestas en el manual oficial e incluyes referencias espec√≠ficas a las im√°genes t√©cnicas cuando est√°n disponibles."
                    },
                    {
                        "role": "user", 
                        "content": prompt
                    }
                ],
                "max_tokens": 1200,
                "temperature": 0.3,
                "top_p": 0.9
            }
            
            async with httpx.AsyncClient(timeout=30.0) as client:
                response = await client.post(
                    "https://api.groq.com/openai/v1/chat/completions",
                    headers=headers,
                    json=payload
                )
                
                if response.status_code == 200:
                    result = response.json()
                    answer = result["choices"][0]["message"]["content"]
                    logger.info("‚úÖ Respuesta generada con Groq + im√°genes reales")
                    
                    return {
                        "text": answer,
                        "images": relevant_images
                    }
                else:
                    logger.error(f"‚ùå Error Groq: {response.status_code} - {response.text}")
                    return self._format_basic_answer(context_chunks)
                    
        except Exception as e:
            logger.error(f"‚ùå Error generando respuesta: {str(e)}")
            return self._format_basic_answer(context_chunks)
    
    def _format_basic_answer(self, context_chunks: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Formatear respuesta b√°sica cuando Groq no est√° disponible"""
        if not context_chunks:
            return {
                "text": "‚ùå No encontr√© informaci√≥n espec√≠fica sobre tu consulta en el manual.",
                "images": []
            }
        
        chunk = context_chunks[0]
        content = chunk.get('content', 'Informaci√≥n no disponible')
        page = chunk.get('page', 0)
        title = chunk.get('title', 'Manual de Mantenimiento')
        
        # Obtener im√°genes REALES
        images = []
        for img in chunk.get('images', []):
            if img.get('url') and not 'placeholder' in img.get('url', ''):
                images.append(img)
        
        # Nota sobre material visual
        visual_note = ""
        if images:
            visual_note = f"\n\nüñºÔ∏è *Incluye {len(images)} imagen(es) t√©cnica(s) del manual*"
        
        text_response = f"""üîß **{title}** (P√°gina {page})

{content[:800]}...{visual_note}

---
üí° *Informaci√≥n del Manual de Mantenimiento de Salones del Reino*
‚ö†Ô∏è *Para consultas espec√≠ficas, contacta al formador de mantenimiento*"""

        return {
            "text": text_response,
            "images": images
        }
    
    async def query(self, query: str, user_id: str = "default", include_images: bool = True) -> Dict[str, Any]:
        """M√©todo principal para procesar consultas con im√°genes REALES del manual"""
        try:
            logger.info(f"üîç Procesando consulta: {query[:50]}... (usuario: {user_id})")
            
            # 1. Generar embedding de la consulta
            query_embedding = await self.get_remote_embedding(query)
            
            # 2. Buscar chunks relevantes en Qdrant
            relevant_chunks = await self.search_qdrant_vectors(query_embedding, limit=3)
            
            if not relevant_chunks:
                return {
                    "answer": "‚ùå No encontr√© informaci√≥n relevante en el manual. Verifica que el manual haya sido procesado correctamente usando el script de Kaggle.",
                    "images": [],
                    "sources": [],
                    "confidence_score": 0.0,
                    "response_time": 0
                }
            
            # 3. Generar respuesta con im√°genes usando Groq
            answer_data = await self.generate_answer_with_groq(query, relevant_chunks)
            
            # 4. Preparar sources con informaci√≥n de im√°genes
            sources = []
            for chunk in relevant_chunks:
                source = f"Manual - P√°gina {chunk['page']}: {chunk['title']}"
                if chunk.get('score', 0) > 0:
                    source += f" (relevancia: {chunk['score']:.2f})"
                if chunk.get('has_images'):
                    source += f" [üñºÔ∏è {chunk.get('image_count', 0)} imagen(es) t√©cnica(s)]"
                sources.append(source)
            
            # 5. Estad√≠sticas
            total_images = len(answer_data["images"])
            max_score = max([c.get('score', 0) for c in relevant_chunks]) if relevant_chunks else 0
            
            if total_images > 0:
                logger.info(f"üñºÔ∏è Respuesta incluye {total_images} imagen(es) REALES del manual")
                for img in answer_data["images"]:
                    logger.info(f"üì∏ Imagen: {img['filename']} - {img['description'][:50]}...")
            
            return {
                "answer": answer_data["text"],
                "images": answer_data["images"] if include_images else [],
                "sources": sources,
                "confidence_score": max_score,
                "response_time": 0,  # Se puede agregar medici√≥n de tiempo
                "metadata": {
                    "query": query,
                    "user_id": user_id,
                    "chunks_found": len(relevant_chunks),
                    "images_found": total_images,
                    "real_images": True,  # Confirma que son im√°genes reales
                    "system_status": "operational_with_real_images" if self.operational else "limited",
                    "embedding_method": "huggingface_remote",
                    "search_method": "qdrant_vector_search",
                    "features": ["text_search", "real_image_support", "remote_embeddings"]
                }
            }
            
        except Exception as e:
            logger.error(f"‚ùå Error en consulta: {str(e)}")
            return {
                "answer": f"‚ùå Error procesando consulta: {str(e)}",
                "images": [],
                "sources": [],
                "metadata": {
                    "error": str(e), 
                    "user_id": user_id,
                    "system_status": "error"
                }
            }
    
    def get_images_by_page(self, page_number: int) -> List[Dict[str, Any]]:
        """Obtener im√°genes REALES de una p√°gina espec√≠fica"""
        try:
            if not self.operational:
                logger.error("‚ùå Sistema no operacional")
                return []
            
            # Buscar chunks de esa p√°gina espec√≠fica
            # Esto requerir√≠a una b√∫squeda por metadatos en Qdrant
            # Por simplicidad, devolver lista vac√≠a si no est√° implementado
            logger.warning(f"‚ö†Ô∏è B√∫squeda por p√°gina {page_number} no implementada a√∫n")
            return []
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo im√°genes de p√°gina {page_number}: {str(e)}")
            return []
    
    def search_related_images(self, query: str) -> List[Dict[str, Any]]:
        """Buscar im√°genes relacionadas con una consulta espec√≠fica"""
        try:
            if not self.operational:
                logger.error("‚ùå Sistema no operacional")
                return []
            
            # Implementar b√∫squeda espec√≠fica de im√°genes basada en descripciones y texto extra√≠do
            logger.warning(f"‚ö†Ô∏è B√∫squeda espec√≠fica de im√°genes para '{query}' no implementada a√∫n")
            return []
            
        except Exception as e:
            logger.error(f"‚ùå Error buscando im√°genes para '{query}': {str(e)}")
            return []
    
    def get_section_by_page(self, page_number: int) -> str:
        """Obtener secci√≥n del manual por n√∫mero de p√°gina"""
        section_map = {
            range(1, 11): "Introducci√≥n y Programa de Mantenimiento",
            range(11, 13): "Equipos",
            range(13, 26): "Edificios",
            range(26, 30): "Sistemas El√©ctricos",
            range(30, 33): "Sistemas Electr√≥nicos",
            range(33, 39): "Sistemas Mec√°nicos",
            range(39, 45): "Reparaciones R√°pidas"
        }
        
        for page_range, section_name in section_map.items():
            if page_number in page_range:
                return section_name
        
        return "Manual de Mantenimiento"
    
    def health_check(self) -> Dict[str, Any]:
        """Verificar estado del sistema con im√°genes REALES"""
        status = {
            "qdrant_configured": bool(self.qdrant_url and self.qdrant_api_key),
            "groq_configured": bool(self.groq_api_key),
            "embedding_method": "huggingface_remote",
            "image_support": "REAL_IMAGES_FROM_PDF",  # Especifica que son im√°genes reales
            "operational": self.operational,
            "overall_status": "healthy" if self.operational else "limited",
            "manual_processed": self.operational,  # Indica si el manual fue procesado
            "features": {
                "vector_search": True,
                "remote_embeddings": True,
                "real_image_extraction": True,
                "ocr_analysis": True,
                "imgbb_storage": True,
                "groq_llm": True,
                "mock_images": False  # Confirma que NO usa mocks
            },
            "requirements": [
                "Manual PDF procesado en Kaggle",
                "Im√°genes extra√≠das y subidas a ImgBB",
                "Chunks con metadatos en Qdrant Cloud",
                "OCR aplicado para descripciones contextuales"
            ] if not self.operational else [
                "‚úÖ Sistema completamente operacional con im√°genes reales"
            ]
        }
        
        return status
